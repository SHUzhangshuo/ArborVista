"""
ä¸‹è½½Embeddingæ¨¡å‹åˆ°æŒ‡å®šç›®å½•
ç”¨äºé¢„å…ˆä¸‹è½½æ¨¡å‹ï¼Œé¿å…è¿è¡Œæ—¶ä¸‹è½½
"""

import os
import sys
from pathlib import Path

def download_model(model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2", 
                   target_dir: str = None):
    """
    ä¸‹è½½HuggingFaceæ¨¡å‹åˆ°æŒ‡å®šç›®å½•
    
    Args:
        model_name: æ¨¡å‹åç§°
        target_dir: ç›®æ ‡ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
    """
    # è®¾ç½®ç›®æ ‡ç›®å½•
    if target_dir is None:
        base_dir = Path(__file__).parent.parent
        target_dir = base_dir / "data" / "vectorDatabase" / "models"
    else:
        target_dir = Path(target_dir)
    
    target_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("ğŸ“¦ ä¸‹è½½Embeddingæ¨¡å‹")
    print("=" * 60)
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜ç›®å½•: {target_dir}")
    print(f"ğŸ¤– æ¨¡å‹åç§°: {model_name}")
    print("-" * 60)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['SENTENCE_TRANSFORMERS_HOME'] = str(target_dir)
    os.environ['HF_HOME'] = str(target_dir)
    
    try:
        print("\nğŸ”„ æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        print("   è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæ¨¡å‹å¤§å°çº¦400MB")
        
        # å¯¼å…¥sentence-transformers
        try:
            from sentence_transformers import SentenceTransformer
        except ImportError:
            print("\nâŒ é”™è¯¯: æœªå®‰è£… sentence-transformers")
            print("   è¯·è¿è¡Œ: pip install sentence-transformers")
            return False
        
        # ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹
        model = SentenceTransformer(model_name, cache_folder=str(target_dir))
        
        # æµ‹è¯•æ¨¡å‹
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹...")
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        embedding = model.encode(test_text)
        
        if embedding is None or len(embedding) == 0:
            print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
            return False
        
        print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œå‘é‡ç»´åº¦: {len(embedding)}")
        print(f"\nâœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print(f"ğŸ“¦ æ¨¡å‹å·²ä¿å­˜åˆ°: {target_dir}")
        
        # æ˜¾ç¤ºæ¨¡å‹æ–‡ä»¶
        print("\nğŸ“‚ æ¨¡å‹æ–‡ä»¶:")
        model_files = list(target_dir.glob("**/*"))
        for file in sorted(model_files)[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
            if file.is_file():
                size = file.stat().st_size / (1024 * 1024)  # MB
                print(f"   - {file.name} ({size:.2f} MB)")
        
        if len(model_files) > 10:
            print(f"   ... è¿˜æœ‰ {len(model_files) - 10} ä¸ªæ–‡ä»¶")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸‹è½½Embeddingæ¨¡å‹")
    parser.add_argument(
        "--model",
        type=str,
        default="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        help="æ¨¡å‹åç§° (é»˜è®¤: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)"
    )
    parser.add_argument(
        "--dir",
        type=str,
        default=None,
        help="ç›®æ ‡ç›®å½• (é»˜è®¤: data/vectorDatabase/models)"
    )
    
    args = parser.parse_args()
    
    success = download_model(
        model_name=args.model,
        target_dir=args.dir
    )
    
    if success:
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨RAGç³»ç»Ÿä¸­ä½¿ç”¨äº†")
        print("=" * 60)
        sys.exit(0)
    else:
        print("\n" + "=" * 60)
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("=" * 60)
        sys.exit(1)


if __name__ == "__main__":
    main()

