import requests
import os
import zipfile
import time
import uuid
import shutil
import subprocess
from urllib.parse import urlparse
from pathlib import Path

class MinerUAPI:
    """MinerU APIå®¢æˆ·ç«¯ - æ”¯æŒåœ¨çº¿APIå’Œæœ¬åœ°è°ƒç”¨"""
    
    def __init__(self, token=None, base_url="https://mineru.net/api/v4", use_local=False, local_url="http://127.0.0.1:30000"):
        """
        åˆå§‹åŒ–MinerUå®¢æˆ·ç«¯
        
        Args:
            token: MinerU API token (åœ¨çº¿æ¨¡å¼éœ€è¦)
            base_url: MinerU API base URL (é»˜è®¤: https://mineru.net/api/v4)
            use_local: æ˜¯å¦ä½¿ç”¨æœ¬åœ°vLLMåç«¯ (é»˜è®¤: False)
            local_url: æœ¬åœ°vLLMåç«¯URL (é»˜è®¤: http://127.0.0.1:30000)
        """
        self.use_local = use_local
        self.local_url = local_url
        
        if not use_local:
            # Online mode
            self.token = token or os.environ.get("MINERU_API_TOKEN")
            if not self.token:
                raise ValueError(
                    "MINERU_API_TOKEN is required for online mode. "
                    "Set it as environment variable or pass as parameter."
                )
            self.base_url = base_url
            self.headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.token}"
            }
            
            # é…ç½®è¯·æ±‚ä¼šè¯ï¼Œç¦ç”¨ä»£ç†
            self.session = requests.Session()
            self.session.proxies = {
                'http': None,
                'https': None
            }
            self.session.verify = True
            self.session.timeout = 30
        else:
            # Local mode - check if mineru command is available
            try:
                result = subprocess.run(
                    ["mineru", "-v"],
                    capture_output=True,
                    check=True,
                    timeout=10,
                    text=True
                )
            except FileNotFoundError:
                raise ValueError(
                    "MinerU command not found. Please install MinerU first:\n"
                    "  1. Install uv: pip install uv\n"
                    "  2. Create conda environment: conda create -n mineru python=3.12 -y\n"
                    "  3. Activate environment: conda activate mineru\n"
                    "  4. Install MinerU: uv pip install mineru"
                )
            except subprocess.TimeoutExpired:
                # If version check times out, still allow initialization
                # The actual command will fail later if mineru is not available
                pass
            except subprocess.CalledProcessError:
                raise ValueError(
                    "MinerU command check failed. Please ensure MinerU is properly installed."
                )
    
    def process_files_batch(self, file_paths, output_dir, batch_index=0, max_files_per_batch=200, language="en", is_ocr=True, enable_formula=True, enable_table=True, layout_model="doclayout_yolo", file_id_map=None, original_filename_map=None):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶ - æ”¯æŒåœ¨çº¿APIå’Œæœ¬åœ°è°ƒç”¨
        
        Args:
            file_id_map: æ–‡ä»¶è·¯å¾„åˆ°file_idçš„æ˜ å°„å­—å…¸ï¼Œç”¨äºæœ¬åœ°æ¨¡å¼æ—¶æŒ‡å®šæ­£ç¡®çš„file_id
            original_filename_map: æ–‡ä»¶è·¯å¾„åˆ°åŸå§‹æ–‡ä»¶åçš„æ˜ å°„å­—å…¸ï¼Œç”¨äºç”Ÿæˆç›®å½•å
        """
        if self.use_local:
            # Local mode: process files sequentially
            return self._process_local_batch(
                file_paths, output_dir, is_ocr, enable_formula,
                enable_table, language, layout_model, file_id_map=file_id_map, original_filename_map=original_filename_map
            )
        else:
            # Online mode - ä¸¥æ ¼æŒ‰ç…§test_input.pyå’Œtest_output.pyçš„é€»è¾‘
            try:
                print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
                
                # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ‰¹æ¬¡IDï¼ˆå¯¹åº”test_input.pyï¼‰
                batch_result = self.generate_batch_idx(
                    file_paths=file_paths,
                    batch_index=batch_index,
                    max_files_per_batch=max_files_per_batch,
                    language=language,
                    is_ocr=is_ocr,
                    enable_formula=enable_formula,
                    enable_table=enable_table,
                    layout_model=layout_model
                )
                
                if not batch_result['success']:
                    return batch_result
                
                batch_id = batch_result['batch_id']
                print(f"âœ… æ‰¹æ¬¡IDç”ŸæˆæˆåŠŸ: {batch_id}")
                
                # ç¬¬äºŒæ­¥ï¼šç­‰å¾…å¤„ç†å®Œæˆ - è½®è¯¢æ£€æŸ¥çŠ¶æ€
                print("â³ ç­‰å¾…å¤„ç†å®Œæˆ...")
                max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
                check_interval = 10   # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                start_time = time.time()
                
                while time.time() - start_time < max_wait_time:
                    # æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€
                    status_result = self.check_batch_status(batch_id)
                    if not status_result['success']:
                        print(f"âŒ æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {status_result['error']}")
                        time.sleep(check_interval)
                        continue
                    
                    if status_result['is_complete']:
                        print(f"âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼æˆåŠŸ: {status_result['completed_files']}/{status_result['total_files']}")
                        break
                    else:
                        print(f"â³ æ‰¹æ¬¡å¤„ç†ä¸­: {status_result['completed_files']}/{status_result['total_files']} (å·²ç­‰å¾… {int(time.time() - start_time)} ç§’)")
                        time.sleep(check_interval)
                else:
                    return {
                        'success': False,
                        'error': f'æ‰¹æ¬¡å¤„ç†è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
                    }
                
                # ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ç»“æœï¼ˆå¯¹åº”test_output.pyï¼‰
                download_result = self.download_by_batch_idx(batch_id, output_dir)
                
                if download_result['success']:
                    return {
                        'success': True,
                        'batch_id': batch_id,
                        'processed_files': download_result['processed_files'],
                        'success_count': download_result['success_count'],
                        'total_count': download_result['total_count'],
                        'output_dir': output_dir,
                        'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {download_result["success_count"]}/{download_result["total_count"]}'
                    }
                else:
                    return download_result
                    
            except Exception as e:
                return {
                    'success': False,
                    'error': f'æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}'
                }
    
    def _process_local_batch(
        self,
        file_paths,
        output_dir,
        is_ocr=True,
        enable_formula=True,
        enable_table=True,
        language="en",
        layout_model="doclayout_yolo",
        file_id_map=None,
        original_filename_map=None
    ):
        """ä½¿ç”¨æœ¬åœ°MinerU vLLMåç«¯æ‰¹é‡å¤„ç†æ–‡ä»¶
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•ï¼ˆæœ€ç»ˆç›®æ ‡ç›®å½•ï¼Œæ¯ä¸ªæ–‡ä»¶ä¼šåˆ›å»ºå¯¹åº”çš„å­ç›®å½•ï¼‰
            file_id_map: æ–‡ä»¶è·¯å¾„åˆ°file_idçš„æ˜ å°„å­—å…¸ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æŒ‡å®šçš„file_id
            original_filename_map: æ–‡ä»¶è·¯å¾„åˆ°åŸå§‹æ–‡ä»¶åçš„æ˜ å°„å­—å…¸ï¼Œç”¨äºç”Ÿæˆç›®å½•å
        """
        results = []
        base_output_path = Path(output_dir)
        base_output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸš€ å¼€å§‹æœ¬åœ°æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
        
        for idx, file_path in enumerate(file_paths, 1):
            file_path_obj = Path(file_path)
            print(f"å¤„ç†æ–‡ä»¶ {idx}/{len(file_paths)}: {file_path_obj.name}")
            
            # è·å–file_idï¼šä¼˜å…ˆä½¿ç”¨file_id_mapï¼Œå¦åˆ™ä½¿ç”¨æ–‡ä»¶å
            if file_id_map and file_path in file_id_map:
                file_id = file_id_map[file_path]
            else:
                file_id = file_path_obj.stem
            
            # è·å–åŸå§‹æ–‡ä»¶åï¼Œç”¨äºç”Ÿæˆç›®å½•å
            if original_filename_map and file_path in original_filename_map:
                original_filename = original_filename_map[file_path]
                # å»æ‰æ‰©å±•åï¼Œå°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
                filename_part = Path(original_filename).stem.replace(' ', '_')
            else:
                # å¦‚æœæ²¡æœ‰åŸå§‹æ–‡ä»¶åï¼Œä½¿ç”¨ä¿å­˜çš„æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                filename_part = file_path_obj.stem.replace(' ', '_')
            
            # ç”Ÿæˆç›®å½•åï¼š{æ–‡ä»¶å}-{file_id}
            dir_name = f"{filename_part}-{file_id}"
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºæœ€ç»ˆç›®æ ‡ç›®å½•ï¼ˆç›´æ¥è¾“å‡ºåˆ°è¿™é‡Œï¼‰
            file_output_dir = base_output_path / dir_name
            file_output_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ æ–‡ä»¶è¾“å‡ºç›®å½•: {file_output_dir}")
            
            result = self._process_local(
                file_path_obj,
                file_output_dir,  # ç›´æ¥è¾“å‡ºåˆ°æœ€ç»ˆç›®å½•
                is_ocr,
                enable_formula,
                enable_table,
                language,
                layout_model,
                file_id=file_id
            )
            
            # è½¬æ¢ç»“æœæ ¼å¼ä»¥åŒ¹é…APIæ¨¡å¼çš„è¿”å›æ ¼å¼
            if result['success']:
                data_id = f"{file_id}_b1"
                
                results.append({
                    'original_name': file_path_obj.name,
                    'data_id': data_id,
                    'output_dir': str(file_output_dir),
                    'success': True
                })
            else:
                results.append({
                    'original_name': file_path_obj.name,
                    'data_id': '',
                    'output_dir': None,
                    'success': False,
                    'error': result.get('error', 'å¤„ç†å¤±è´¥')
                })
        
        success_count = sum(1 for r in results if r['success'])
        return {
            'success': success_count > 0,
            'processed_files': results,
            'success_count': success_count,
            'total_count': len(results),
            'output_dir': str(base_output_path),
            'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(results)}'
        }
    
    def _process_local(
        self,
        input_path: Path,
        output_path: Path,
        is_ocr: bool = True,
        enable_formula: bool = True,
        enable_table: bool = True,
        language: str = "en",
        layout_model: str = "doclayout_yolo",
        file_id: str = None
    ):
        """ä½¿ç”¨æœ¬åœ°MinerU vLLMåç«¯å¤„ç†å•ä¸ªæ–‡ä»¶
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•ï¼ˆMinerUä¼šåœ¨è¿™é‡Œåˆ›å»ºå­ç›®å½•ï¼‰
            file_id: æ–‡ä»¶IDï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æ­¤IDï¼Œå¦åˆ™ä½¿ç”¨input_path.stem
        """
        try:
            # Build mineru command
            cmd = [
                "mineru",
                "-p", str(input_path),
                "-o", str(output_path),
                "-b", "vlm-http-client",
                "-u", self.local_url
            ]
            
            # Execute command
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600  # 10 minutes timeout
            )
            
            if result.returncode == 0:
                # MinerU ä¼šåœ¨è¾“å‡ºç›®å½•ä¸‹åˆ›å»ºå­ç›®å½•ï¼Œéœ€è¦å°†å†…å®¹ç§»åŠ¨åˆ°ç›®æ ‡ç›®å½•
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
                all_files = list(output_path.rglob("*"))
                if all_files:
                    print(f"âœ… MinerU å¤„ç†å®Œæˆï¼Œè¾“å‡ºç›®å½•: {output_path}")
                    
                    # æŸ¥æ‰¾æ‰€æœ‰ç›´æ¥å­ç›®å½•
                    all_subdirs = [d for d in output_path.iterdir() if d.is_dir()]
                    
                    if all_subdirs:
                        print(f"ğŸ“ å‘ç° {len(all_subdirs)} ä¸ªå­ç›®å½•ï¼Œå¼€å§‹ç§»åŠ¨å†…å®¹åˆ°ç›®æ ‡ç›®å½•...")
                        
                        # ä¼˜å…ˆæŸ¥æ‰¾ä»¥ file_id å‘½åçš„å­ç›®å½•
                        target_subdir = None
                        if file_id:
                            for subdir in all_subdirs:
                                if subdir.name == file_id:
                                    target_subdir = subdir
                                    print(f"   æ‰¾åˆ° file_id å­ç›®å½•: {subdir.name}")
                                    break
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° file_id å­ç›®å½•ï¼ŒæŸ¥æ‰¾æ•°å­—å‘½åçš„å­ç›®å½•ï¼ˆå¦‚ 1/, 2/ï¼‰
                        if not target_subdir:
                            digit_subdirs = [d for d in all_subdirs if d.name.isdigit()]
                            if digit_subdirs:
                                target_subdir = digit_subdirs[0]
                                print(f"   æ‰¾åˆ°æ•°å­—å­ç›®å½•: {target_subdir.name}")
                        
                        # å¦‚æœæ‰¾åˆ°äº†ç›®æ ‡å­ç›®å½•ï¼Œå°†å…¶å†…å®¹ï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰ç§»åŠ¨åˆ°ä¸»ç›®å½•
                        if target_subdir:
                            print(f"   å¤„ç†å­ç›®å½•: {target_subdir.name}")
                            
                            # æ£€æŸ¥å­ç›®å½•ä¸­æ˜¯å¦æœ‰ vlm å­ç›®å½•ï¼ˆæœ¬åœ°æ¨¡å¼ç‰¹æœ‰ï¼‰
                            vlm_subdir = target_subdir / "vlm"
                            if vlm_subdir.exists() and vlm_subdir.is_dir():
                                print(f"   å‘ç° vlm å­ç›®å½•ï¼Œå¤„ç† vlm ç›®å½•å†…å®¹...")
                                # å°† vlm ç›®å½•ä¸­çš„å†…å®¹ç§»åŠ¨åˆ° file_id å­ç›®å½•
                                for item in vlm_subdir.iterdir():
                                    target_item = target_subdir / item.name
                                    
                                    # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œè·³è¿‡æˆ–æ·»åŠ åç¼€
                                    if target_item.exists():
                                        if item.is_file():
                                            base_name = item.stem
                                            extension = item.suffix
                                            counter = 1
                                            while target_item.exists():
                                                target_item = target_subdir / f"{base_name}_{counter}{extension}"
                                                counter += 1
                                        else:
                                            # å¦‚æœæ˜¯ç›®å½•ï¼Œæ·»åŠ åç¼€
                                            counter = 1
                                            while target_item.exists():
                                                target_item = target_subdir / f"{item.name}_{counter}"
                                                counter += 1
                                    
                                    # ç§»åŠ¨æ–‡ä»¶æˆ–ç›®å½•ï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰
                                    shutil.move(str(item), str(target_item))
                                    if item.is_file():
                                        print(f"      âœ… ç§»åŠ¨æ–‡ä»¶: {item.name}")
                                    else:
                                        print(f"      âœ… ç§»åŠ¨ç›®å½•: {item.name}")
                                
                                # åˆ é™¤ç©ºçš„ vlm ç›®å½•
                                try:
                                    if vlm_subdir.exists():
                                        shutil.rmtree(vlm_subdir)
                                        print(f"      ğŸ—‘ï¸ åˆ é™¤ vlm å­ç›®å½•")
                                except Exception as e:
                                    print(f"      âš ï¸ åˆ é™¤ vlm å­ç›®å½•å¤±è´¥: {e}")
                            
                            # éå†å­ç›®å½•ä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆæ–‡ä»¶å’Œç›®å½•ï¼‰
                            for item in target_subdir.iterdir():
                                target_item = output_path / item.name
                                
                                # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œè·³è¿‡æˆ–æ·»åŠ åç¼€
                                if target_item.exists():
                                    if item.is_file():
                                        base_name = item.stem
                                        extension = item.suffix
                                        counter = 1
                                        while target_item.exists():
                                            target_item = output_path / f"{base_name}_{counter}{extension}"
                                            counter += 1
                                    else:
                                        # å¦‚æœæ˜¯ç›®å½•ï¼Œæ·»åŠ åç¼€
                                        counter = 1
                                        while target_item.exists():
                                            target_item = output_path / f"{item.name}_{counter}"
                                            counter += 1
                                
                                # ç§»åŠ¨æ–‡ä»¶æˆ–ç›®å½•ï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰
                                shutil.move(str(item), str(target_item))
                                if item.is_file():
                                    print(f"   âœ… ç§»åŠ¨æ–‡ä»¶: {item.name}")
                                else:
                                    print(f"   âœ… ç§»åŠ¨ç›®å½•: {item.name}")
                            
                            # åˆ é™¤ç©ºçš„å­ç›®å½•
                            try:
                                if target_subdir.exists():
                                    shutil.rmtree(target_subdir)
                                    print(f"   ğŸ—‘ï¸ åˆ é™¤å­ç›®å½•: {target_subdir.name}")
                            except Exception as e:
                                print(f"   âš ï¸ åˆ é™¤å­ç›®å½•å¤±è´¥: {e}")
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå­ç›®å½•ï¼Œå¤„ç†æ‰€æœ‰å­ç›®å½•ï¼ˆæ‰å¹³åŒ–ï¼‰
                            print(f"   âš ï¸ æœªæ‰¾åˆ°ç‰¹å®šå­ç›®å½•ï¼Œå¤„ç†æ‰€æœ‰å­ç›®å½•...")
                            for subdir in all_subdirs:
                                print(f"   å¤„ç†å­ç›®å½•: {subdir.name}")
                                # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶
                                for item in subdir.rglob("*"):
                                    if item.is_file():
                                        # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºå­ç›®å½•ï¼‰
                                        rel_path = item.relative_to(subdir)
                                        # ä¿ç•™ç›®å½•ç»“æ„
                                        target_path = output_path / rel_path
                                        
                                        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
                                        target_path.parent.mkdir(parents=True, exist_ok=True)
                                        
                                        # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
                                        if target_path.exists():
                                            base_name = target_path.stem
                                            extension = target_path.suffix
                                            parent_dir = target_path.parent
                                            counter = 1
                                            while target_path.exists():
                                                target_path = parent_dir / f"{base_name}_{counter}{extension}"
                                                counter += 1
                                        
                                        # ç§»åŠ¨æ–‡ä»¶
                                        shutil.move(str(item), str(target_path))
                                        print(f"   âœ… ç§»åŠ¨æ–‡ä»¶: {rel_path}")
                                
                                # åˆ é™¤ç©ºçš„å­ç›®å½•
                                try:
                                    if subdir.exists():
                                        shutil.rmtree(subdir)
                                        print(f"   ğŸ—‘ï¸ åˆ é™¤å­ç›®å½•: {subdir.name}")
                                except Exception as e:
                                    print(f"   âš ï¸ åˆ é™¤å­ç›®å½•å¤±è´¥: {e}")
                    
                    # å†æ¬¡æ£€æŸ¥ç›®æ ‡ç›®å½•ä¸­çš„å†…å®¹
                    final_items = list(output_path.iterdir())
                    print(f"ğŸ“ æœ€ç»ˆå†…å®¹æ•°é‡: {len(final_items)}")
                    for item in final_items:
                        if item.is_file():
                            print(f"   ğŸ“„ {item.name}")
                        else:
                            print(f"   ğŸ“ {item.name}/")
                    
                    return {
                        'success': True,
                        'input_path': str(input_path),
                        'output_dir': str(output_path),
                        'message': 'File processed successfully'
                    }
                else:
                    return {
                        'success': False,
                        'error': f'No markdown file found in output directory: {output_path}. '
                                f'Command stdout: {result.stdout[:200] if result.stdout else "None"}'
                    }
            else:
                error_msg = result.stderr if result.stderr else result.stdout
                return {
                    'success': False,
                    'error': f'MinerU command failed (return code: {result.returncode}). '
                            f'Error: {error_msg}'
                }
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': 'Processing timeout (exceeded 10 minutes)'
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'Processing failed: {str(e)}'
            }
    
    def submit_task(self, file_path, is_ocr=True, enable_formula=False, enable_table=True, language="en", layout_model="doclayout_yolo"):
        """æäº¤å•ä¸ªæ–‡ä»¶å¤„ç†ä»»åŠ¡åˆ°åœ¨çº¿API"""
        if self.use_local:
            return {
                'success': False,
                'error': 'submit_task is only available in online mode. Use process_file instead.'
            }
        
        try:
            file_path_obj = Path(file_path)
            if not file_path_obj.exists():
                return {
                    'success': False,
                    'error': f'File not found: {file_path}'
                }
            
            # Get upload URL
            response = self.session.post(
                f"{self.base_url}/file-urls",
                headers=self.headers,
                json={
                    "name": file_path_obj.name,
                    "is_ocr": is_ocr,
                    "enable_formula": enable_formula,
                    "enable_table": enable_table,
                    "language": language,
                    "layout_model": layout_model
                }
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'Request failed with status {response.status_code}'
                }
            
            result = response.json()
            if result.get("code") != 0:
                return {
                    'success': False,
                    'error': result.get("msg", "Unknown error")
                }
            
            # Upload file
            upload_url = result["data"]["file_url"]
            task_id = result["data"]["task_id"]
            
            with open(file_path_obj, 'rb') as f:
                upload_response = self.session.put(upload_url, data=f)
                if upload_response.status_code not in [200, 201]:
                    return {
                        'success': False,
                        'error': f'Upload failed with status {upload_response.status_code}'
                    }
            
            return {
                'success': True,
                'task_id': task_id
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'Submit task failed: {str(e)}'
            }
    
    def check_task_status(self, task_id):
        """æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
        try:
            response = self.session.get(
                f"{self.base_url}/extract/task/{task_id}",
                headers=self.headers
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    data = result.get('data', {})
                    return {
                        'success': True,
                        'state': data.get('state'),
                        'zip_url': data.get('full_zip_url'),
                        'error_msg': data.get('err_msg', '')
                    }
                else:
                    return {
                        'success': False,
                        'error': result.get('msg', 'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥')
                    }
            else:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}'
            }
    
    def download_and_extract_result(self, zip_url, output_dir):
        """ä¸‹è½½å¹¶è§£å‹ç»“æœæ–‡ä»¶"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ä»URLä¸­æå–æ–‡ä»¶å
            parsed_url = urlparse(zip_url)
            filename = os.path.basename(parsed_url.path)
            if not filename.endswith('.zip'):
                filename = f"mineru_result_{int(time.time())}.zip"
            
            zip_path = output_path / filename
            
            print(f"å¼€å§‹ä¸‹è½½æ–‡ä»¶: {zip_url}")
            print(f"ä¿å­˜åˆ°: {zip_path}")
            
            # ä¸‹è½½æ–‡ä»¶
            response = self.session.get(zip_url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\rä¸‹è½½è¿›åº¦: {percent:.1f}%", end='', flush=True)
            
            print(f"\nä¸‹è½½å®Œæˆ: {zip_path}")
            
            # è§£å‹æ–‡ä»¶
            extract_dir = output_path / filename.replace('.zip', '')
            print(f"å¼€å§‹è§£å‹åˆ°: {extract_dir}")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            print(f"è§£å‹å®Œæˆ: {extract_dir}")
            
            # æŸ¥æ‰¾markdownæ–‡ä»¶
            md_files = list(extract_dir.rglob("*.md"))
            if md_files:
                # å°†markdownæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•çš„æ ¹ç›®å½•
                md_file = md_files[0]
                target_md = extract_dir / "result.md"
                md_file.rename(target_md)
                print(f"æ‰¾åˆ°markdownæ–‡ä»¶: {target_md}")
            
            # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
            image_files = list(extract_dir.rglob("*.jpg")) + list(extract_dir.rglob("*.png"))
            if image_files:
                # åˆ›å»ºimagesç›®å½•
                images_dir = extract_dir / "images"
                images_dir.mkdir(exist_ok=True)
                
                # ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶åˆ°imagesç›®å½•
                for img_file in image_files:
                    target_img = images_dir / img_file.name
                    img_file.rename(target_img)
                    print(f"ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶: {target_img}")
            
            return {
                'success': True,
                'extract_dir': str(extract_dir),
                'md_file': str(extract_dir / "result.md") if md_files else None,
                'images_dir': str(extract_dir / "images") if image_files else None
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ä¸‹è½½æˆ–è§£å‹å¤±è´¥: {str(e)}'
            }
    
    def get_batch_results(self, batch_id, output_dir):
        """è·å–æ‰¹é‡å¤„ç†ç»“æœ"""
        try:
            print(f"ğŸ“¦ è·å–æ‰¹é‡å¤„ç†ç»“æœ: {batch_id}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # è·å–æ‰¹é‡ç»“æœ
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹é‡ç»“æœå¤±è´¥')
                }
            
            # å¤„ç†ç»“æœæ•°æ®
            data_list = batch_data['data']['extract_result']
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item['file_name']
                    
                    # ç”Ÿæˆæœ€ç»ˆè·¯å¾„
                    base_name = os.path.splitext(original_name)[0]
                    final_filename = f"{base_name}.md"
                    output_file_path = output_path / final_filename
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = output_path / f"temp_{item['data_id']}"
                        temp_dir.mkdir(exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = temp_dir / zip_name
                        
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹å¹¶å¤„ç†æ–‡ä»¶
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            # æœç´¢full.mdæ–‡ä»¶
                            target_file = None
                            for file_info in zip_ref.infolist():
                                if os.path.basename(file_info.filename) == 'full.md':
                                    target_file = file_info
                                    break
                            
                            if target_file:
                                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                                zip_ref.extract(target_file, temp_dir)
                                
                                # æ„å»ºå®Œæ•´è·¯å¾„
                                extracted_path = temp_dir / target_file.filename
                                
                                # ç§»åŠ¨å¹¶é‡å‘½å
                                shutil.move(str(extracted_path), str(output_file_path))
                                print(f"âœ… æˆåŠŸå¤„ç†ï¼š{original_name} -> {output_file_path}")
                                
                                processed_files.append({
                                    'original_name': original_name,
                                    'output_path': str(output_file_path),
                                    'success': True
                                })
                            else:
                                print(f"âš ï¸ è­¦å‘Šï¼š{zip_name} ä¸­æœªæ‰¾åˆ°full.mdæ–‡ä»¶")
                                processed_files.append({
                                    'original_name': original_name,
                                    'output_path': None,
                                    'success': False,
                                    'error': 'æœªæ‰¾åˆ°full.mdæ–‡ä»¶'
                                })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"âŒ æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"âŒ å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if temp_dir.exists():
                            shutil.rmtree(temp_dir)
            
            return {
                'success': True,
                'processed_files': processed_files,
                'output_dir': str(output_path)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}'
            }
    
    def submit_batch_task(self, file_paths, is_ocr=True, enable_formula=True, language="en", layout_model="doclayout_yolo", enable_table=True, max_files_per_batch=200):
        """æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        try:
            print(f"ğŸ“¦ æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡ï¼Œæ–‡ä»¶æ•°é‡: {len(file_paths)}")
            
            # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
            all_batch_ids = []
            total_files = len(file_paths)
            
            for batch_idx in range(0, total_files, max_files_per_batch):
                batch_files = file_paths[batch_idx:batch_idx + max_files_per_batch]
                print(f"å¤„ç†ç¬¬ {batch_idx // max_files_per_batch + 1} æ‰¹æ¬¡ï¼Œæ–‡ä»¶æ•°é‡: {len(batch_files)}")
                
                # æ„å»ºæ–‡ä»¶æ•°æ® - æ ¹æ®æœ€æ–°APIæ–‡æ¡£æ ¼å¼
                files_data = []
                for file_path in batch_files:
                    if os.path.exists(file_path):
                        file_name = os.path.basename(file_path)
                        files_data.append({
                            "name": file_name,
                            "is_ocr": is_ocr,
                            "data_id": f"{os.path.splitext(file_name)[0]}_b{batch_idx // max_files_per_batch + 1}",
                        })
                
                if not files_data:
                    print(f"æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶")
                    continue
                
                # æäº¤æ‰¹æ¬¡ä»»åŠ¡ - é»˜è®¤ä½¿ç”¨vlmæ¨¡å‹
                batch_result = self._submit_single_batch(files_data, batch_files, enable_formula, language, layout_model, enable_table, model_version="vlm")
                if batch_result['success']:
                    all_batch_ids.append(batch_result['batch_id'])
                    print(f"âœ… æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æäº¤æˆåŠŸï¼Œæ‰¹æ¬¡ID: {batch_result['batch_id']}")
                else:
                    print(f"âŒ æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æäº¤å¤±è´¥: {batch_result['error']}")
            
            if all_batch_ids:
                return {
                    'success': True,
                    'batch_ids': all_batch_ids,
                    'message': f'æˆåŠŸæäº¤ {len(all_batch_ids)} ä¸ªæ‰¹æ¬¡'
                }
            else:
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰æ‰¹æ¬¡æäº¤å¤±è´¥'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æäº¤æ‰¹é‡ä»»åŠ¡å¤±è´¥: {str(e)}'
            }
    
    def _submit_single_batch(self, files_data, file_paths, enable_formula, language, layout_model, enable_table, model_version="vlm"):
        """æäº¤å•ä¸ªæ‰¹æ¬¡ä»»åŠ¡"""
        try:
            # è·å–ä¸Šä¼ URL - æ ¹æ®æœ€æ–°APIæ–‡æ¡£
            response = self.session.post(
                f"{self.base_url}/file-urls/batch",
                headers=self.headers,
                json={
                    "files": files_data,
                    "model_version": model_version,
                    "enable_formula": enable_formula,
                    "enable_table": enable_table,
                    "language": language
                }
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}'
                }
            
            result = response.json()
            if result["code"] != 0:
                return {
                    'success': False,
                    'error': f'ç”³è¯·å¤±è´¥ï¼ŒåŸå› ï¼š{result.get("msg", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¸Šä¼ æ–‡ä»¶
            batch_id = result["data"]["batch_id"]
            urls = result["data"]["file_urls"]
            success_count = 0
            
            for idx, (url, file_path) in enumerate(zip(urls, file_paths)):
                if os.path.exists(file_path):
                    with open(file_path, 'rb') as f:
                        res = self.session.put(url, data=f)
                        if res.status_code in [200, 201]:
                            success_count += 1
                        else:
                            print(f"âŒ å¤±è´¥æ–‡ä»¶ï¼š{os.path.basename(file_path)}ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}")
            
            print(f"ğŸ“¤ æ‰¹æ¬¡ä¸Šä¼ å®Œæˆ | æˆåŠŸï¼š{success_count}/{len(file_paths)} | æ‰¹æ¬¡IDï¼š{batch_id}")
            
            return {
                'success': True,
                'batch_id': batch_id,
                'uploaded_count': success_count,
                'total_count': len(file_paths)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æäº¤æ‰¹æ¬¡å¤±è´¥: {str(e)}'
            }
    
    def check_batch_status(self, batch_id):
        """æ£€æŸ¥æ‰¹é‡å¤„ç†çŠ¶æ€"""
        try:
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹é‡çŠ¶æ€å¤±è´¥')
                }
            
            # åˆ†æå¤„ç†çŠ¶æ€ - æ ¹æ®æœ€æ–°APIæ–‡æ¡£
            data_list = batch_data['data']['extract_result']
            total_files = len(data_list)
            completed_files = len([item for item in data_list if item.get('state') == 'done'])
            failed_files = len([item for item in data_list if item.get('state') == 'failed'])
            processing_files = len([item for item in data_list if item.get('state') in ['pending', 'running', 'converting', 'waiting-file']])
            
            return {
                'success': True,
                'batch_id': batch_id,
                'total_files': total_files,
                'completed_files': completed_files,
                'failed_files': failed_files,
                'processing_files': processing_files,
                'is_complete': completed_files + failed_files == total_files,
                'data_list': data_list
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æ£€æŸ¥æ‰¹é‡çŠ¶æ€å¤±è´¥: {str(e)}'
            }
    
    def download_batch_results(self, batch_id, output_dir):
        """ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ"""
        try:
            print(f"ğŸ“¥ ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ: {batch_id}")
            
            # æ£€æŸ¥æ‰¹é‡çŠ¶æ€
            status_result = self.check_batch_status(batch_id)
            if not status_result['success']:
                return status_result
            
            if not status_result['is_complete']:
                return {
                    'success': False,
                    'error': f'æ‰¹é‡å¤„ç†æœªå®Œæˆï¼Œå·²å®Œæˆ: {status_result["completed_files"]}/{status_result["total_files"]}'
                }
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            data_list = status_result['data_list']
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item['file_name']
                    data_id = item['data_id']
                    
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„ç›®å½•ï¼Œä½¿ç”¨data_idä½œä¸ºç›®å½•å
                    file_output_dir = output_path / data_id
                    file_output_dir.mkdir(exist_ok=True)
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = output_path / f"temp_{data_id}"
                        temp_dir.mkdir(exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = temp_dir / zip_name
                        
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹æ•´ä¸ªZIPæ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(file_output_dir)
                            print(f"âœ… æˆåŠŸå¤„ç†ï¼š{original_name} -> {file_output_dir}")
                        
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': str(file_output_dir),
                            'success': True
                        })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"âŒ æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"âŒ å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if temp_dir.exists():
                            shutil.rmtree(temp_dir)
                elif item.get('state') == 'failed':
                    print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': 'æ–‡ä»¶å¤„ç†å¤±è´¥'
                    })
            
            return {
                'success': True,
                'batch_id': batch_id,
                'processed_files': processed_files,
                'output_dir': str(output_path)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ä¸‹è½½æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}'
            }
    
    def process_batch_files(self, file_paths, output_dir, is_ocr=True, enable_formula=True, language="en", max_wait_time=1800):
        """å¤„ç†æ‰¹é‡æ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
        try:
            print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
            
            # 1. æäº¤æ‰¹é‡ä»»åŠ¡
            submit_result = self.submit_batch_task(
                file_paths, 
                is_ocr=is_ocr, 
                enable_formula=enable_formula, 
                language=language
            )
            if not submit_result['success']:
                return submit_result
            
            batch_ids = submit_result['batch_ids']
            print(f"ğŸ“‹ æˆåŠŸæäº¤ {len(batch_ids)} ä¸ªæ‰¹æ¬¡")
            
            # 2. ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
            print("â³ ç­‰å¾…æ‰¹é‡å¤„ç†å®Œæˆ...")
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                all_complete = True
                
                for batch_id in batch_ids:
                    status_result = self.check_batch_status(batch_id)
                    if not status_result['success']:
                        print(f"âŒ æ£€æŸ¥æ‰¹æ¬¡ {batch_id} çŠ¶æ€å¤±è´¥: {status_result['error']}")
                        continue
                    
                    if not status_result['is_complete']:
                        all_complete = False
                        print(f"â³ æ‰¹æ¬¡ {batch_id} å¤„ç†ä¸­: {status_result['completed_files']}/{status_result['total_files']}")
                
                if all_complete:
                    print("âœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆ")
                    break
                
                # ç­‰å¾…30ç§’åå†æ¬¡æ£€æŸ¥
                time.sleep(30)
            
            if not all_complete:
                return {
                    'success': False,
                    'error': f'æ‰¹é‡å¤„ç†è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
                }
            
            # 3. ä¸‹è½½æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
            all_processed_files = []
            for batch_id in batch_ids:
                download_result = self.download_batch_results(batch_id, output_dir)
                if download_result['success']:
                    all_processed_files.extend(download_result['processed_files'])
                else:
                    print(f"âŒ ä¸‹è½½æ‰¹æ¬¡ {batch_id} ç»“æœå¤±è´¥: {download_result['error']}")
            
            success_count = len([f for f in all_processed_files if f['success']])
            total_count = len(all_processed_files)
            
            return {
                'success': True,
                'processed_files': all_processed_files,
                'success_count': success_count,
                'total_count': total_count,
                'output_dir': output_dir,
                'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{total_count}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}'
            }

    def generate_batch_idx(self, file_paths, batch_index=0, max_files_per_batch=200, language="ch", is_ocr=True, enable_formula=True, enable_table=True, layout_model="doclayout_yolo"):
        """ç”Ÿæˆæ‰¹æ¬¡ID - å¯¹åº”test_input.pyçš„åŠŸèƒ½"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            valid_files = []
            for file_path in file_paths:
                if os.path.exists(file_path):
                    valid_files.append(file_path)
                else:
                    print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
            
            if not valid_files:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯å¤„ç†'
                }
            
            print(f"æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
            print(f"å¤„ç†ç¬¬ {batch_index} æ‰¹æ¬¡")
            
            # è®¡ç®—æ‰¹æ¬¡æ–‡ä»¶èŒƒå›´
            batch_idx = max_files_per_batch * batch_index
            batch_files = valid_files[batch_idx : batch_idx + max_files_per_batch]
            
            if not batch_files:
                return {
                    'success': False,
                    'error': f'ç¬¬ {batch_index} æ‰¹æ¬¡æ²¡æœ‰æ–‡ä»¶å¯å¤„ç†'
                }
            
            # æ„å»ºæ–‡ä»¶æ•°æ® - æ ¹æ®æœ€æ–°APIæ–‡æ¡£æ ¼å¼
            files_data = [{
                "name": os.path.basename(file_path),
                "is_ocr": is_ocr,
                "data_id": f"{os.path.splitext(os.path.basename(file_path))[0]}_b{batch_index + 1}",
            } for file_path in batch_files]
            
            print(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_index + 1} æ‰¹æ¬¡ï¼ˆå…± {len(batch_files)} ä¸ªæ–‡ä»¶ï¼‰")
            
            # è·å–ä¸Šä¼ URL - æ ¹æ®æœ€æ–°APIæ–‡æ¡£
            response = self.session.post(
                f"{self.base_url}/file-urls/batch",
                headers=self.headers,
                json={
                    "files": files_data,
                    "model_version": "vlm",  # é»˜è®¤ä½¿ç”¨vlmï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨pipeline
                    "enable_formula": enable_formula,
                    "enable_table": enable_table,
                    "language": language
                }
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}'
                }
            
            result = response.json()
            if result["code"] != 0:
                return {
                    'success': False,
                    'error': f'ç”³è¯·å¤±è´¥ï¼ŒåŸå› ï¼š{result.get("msg", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¸Šä¼ æ–‡ä»¶
            batch_id = result["data"]["batch_id"]
            urls = result["data"]["file_urls"]
            success_count = 0
            
            for idx, (url, file_path) in enumerate(zip(urls, batch_files)):
                with open(file_path, 'rb') as f:
                    res = self.session.put(url, data=f)
                    if res.status_code in [200, 201]:
                        success_count += 1
                    else:
                        print(f"å¤±è´¥æ–‡ä»¶ï¼š{os.path.basename(file_path)}ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}")
            
            print(f"ç¬¬ {batch_index + 1} æ‰¹æ¬¡å®Œæˆ | æˆåŠŸï¼š{success_count}/{len(batch_files)} | æ‰¹æ¬¡IDï¼š{batch_id}")
            
            return {
                'success': True,
                'batch_id': batch_id,
                'uploaded_count': success_count,
                'total_count': len(batch_files),
                'message': f'ç¬¬ {batch_index + 1} æ‰¹æ¬¡æäº¤æˆåŠŸï¼Œæ‰¹æ¬¡ID: {batch_id}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ‰¹æ¬¡IDå¤±è´¥: {str(e)}'
            }
    
    def download_by_batch_idx(self, batch_id, output_dir):
        """åˆ©ç”¨æ‰¹æ¬¡IDä¸‹è½½ç»“æœ - å¯¹åº”test_output.pyçš„åŠŸèƒ½"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            print(f"å¼€å§‹ä¸‹è½½æ‰¹æ¬¡ {batch_id} çš„ç»“æœ...")
            
            # å…ˆæ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½å¤„ç†å®Œæˆ
            status_result = self.check_batch_status(batch_id)
            if not status_result['success']:
                return {
                    'success': False,
                    'error': f'æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {status_result["error"]}'
                }
            
            if not status_result['is_complete']:
                return {
                    'success': False,
                    'error': f'æ‰¹æ¬¡å¤„ç†æœªå®Œæˆï¼Œå·²å®Œæˆ: {status_result["completed_files"]}/{status_result["total_files"]}ï¼Œè¯·ç¨åé‡è¯•'
                }
            
            # è·å–æ‰¹æ¬¡ç»“æœ
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹æ¬¡ç»“æœå¤±è´¥')
                }
            
            # æ­£ç¡®è®¿é—®æ•°æ®è·¯å¾„
            data_list = batch_data['data']['extract_result']
            
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item.get('file_name', '')
                    data_id = item.get('data_id', '')
                    
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„ç›®å½•ï¼Œä½¿ç”¨data_idä½œä¸ºç›®å½•å
                    file_output_dir = os.path.join(output_dir, data_id)
                    os.makedirs(file_output_dir, exist_ok=True)
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = os.path.join(output_dir, f"temp_{data_id}")
                        os.makedirs(temp_dir, exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = os.path.join(temp_dir, zip_name)
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹æ•´ä¸ªZIPæ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(file_output_dir)
                            print(f"æˆåŠŸå¤„ç†ï¼š{original_name} -> {file_output_dir}")
                        
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': file_output_dir,
                            'success': True
                        })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_dir):
                            shutil.rmtree(temp_dir)
                elif item.get('state') == 'running':
                    print(f"â³ æ–‡ä»¶ä»åœ¨å¤„ç†ä¸­ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')} - çŠ¶æ€: {item.get('state')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': 'æ–‡ä»¶ä»åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åé‡è¯•'
                    })
                else:
                    print(f"æ–‡ä»¶å¤„ç†çŠ¶æ€å¼‚å¸¸ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')} - {item.get('state', 'æœªçŸ¥çŠ¶æ€')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': f'å¤„ç†çŠ¶æ€å¼‚å¸¸: {item.get("state", "æœªçŸ¥çŠ¶æ€")}'
                    })
            
            success_count = len([f for f in processed_files if f['success']])
            total_count = len(processed_files)
            
            return {
                'success': True,
                'batch_id': batch_id,
                'processed_files': processed_files,
                'success_count': success_count,
                'total_count': total_count,
                'output_dir': output_dir,
                'message': f'æ‰¹æ¬¡ {batch_id} ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{total_count}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'åˆ©ç”¨æ‰¹æ¬¡IDä¸‹è½½å¤±è´¥: {str(e)}'
            }

    def process_file(self, file_path, output_dir, is_ocr=True, enable_formula=False, enable_table=True, language="en", layout_model="doclayout_yolo", max_wait_time=300):
        """å¤„ç†æ–‡ä»¶çš„å®Œæ•´æµç¨‹ - æ”¯æŒåœ¨çº¿APIå’Œæœ¬åœ°è°ƒç”¨"""
        if self.use_local:
            # Local mode
            return self._process_local(
                Path(file_path),
                Path(output_dir),
                is_ocr,
                enable_formula,
                enable_table,
                language,
                layout_model
            )
        else:
            # Online mode
            try:
                # 1. æäº¤ä»»åŠ¡
                print("æäº¤æ–‡ä»¶å¤„ç†ä»»åŠ¡...")
                submit_result = self.submit_task(file_path, is_ocr, enable_formula)
                if not submit_result['success']:
                    return submit_result
                
                task_id = submit_result['task_id']
                print(f"ä»»åŠ¡ID: {task_id}")
                
                # 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€
                print("ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
                start_time = time.time()
                
                while time.time() - start_time < max_wait_time:
                    status_result = self.check_task_status(task_id)
                    if not status_result['success']:
                        return status_result
                    
                    state = status_result['state']
                    print(f"ä»»åŠ¡çŠ¶æ€: {state}")
                    
                    if state == 'done':
                        zip_url = status_result['zip_url']
                        if zip_url:
                            # 3. ä¸‹è½½å¹¶è§£å‹ç»“æœ
                            print("ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½ç»“æœ...")
                            return self.download_and_extract_result(zip_url, output_dir)
                        else:
                            return {
                                'success': False,
                                'error': 'ä»»åŠ¡å®Œæˆä½†æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥'
                            }
                    elif state == 'failed':
                        return {
                            'success': False,
                            'error': f'ä»»åŠ¡å¤±è´¥: {status_result.get("error_msg", "æœªçŸ¥é”™è¯¯")}'
                        }
                    
                    # ç­‰å¾…5ç§’åå†æ¬¡æ£€æŸ¥
                    time.sleep(5)
                
                return {
                    'success': False,
                    'error': f'ä»»åŠ¡è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
                }
                
            except Exception as e:
                return {
                    'success': False,
                    'error': f'å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}'
                }
