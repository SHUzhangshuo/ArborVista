import requests
import os
import zipfile
import time
import uuid
import shutil
from urllib.parse import urlparse
from pathlib import Path

class MinerUAPI:
    """MinerU APIå®¢æˆ·ç«¯"""
    
    def __init__(self, token, base_url="https://mineru.net/api/v4"):
        self.token = token
        self.base_url = base_url
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {token}"
        }
        
        # é…ç½®è¯·æ±‚ä¼šè¯ï¼Œç¦ç”¨ä»£ç†
        self.session = requests.Session()
        self.session.proxies = {
            'http': None,
            'https': None
        }
        self.session.verify = True
        self.session.timeout = 30
    
    def process_files_batch(self, file_paths, output_dir, batch_index=0, max_files_per_batch=200, language="en", is_ocr=True, enable_formula=True, enable_table=True, layout_model="doclayout_yolo"):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶ - ä¸¥æ ¼æŒ‰ç…§test_input.pyå’Œtest_output.pyçš„é€»è¾‘"""
        try:
            print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
            
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ‰¹æ¬¡IDï¼ˆå¯¹åº”test_input.pyï¼‰
            batch_result = self.generate_batch_idx(
                file_paths=file_paths,
                batch_index=batch_index,
                max_files_per_batch=max_files_per_batch,
                language=language,
                is_ocr=is_ocr,
                enable_formula=enable_formula,
                enable_table=enable_table,
                layout_model=layout_model
            )
            
            if not batch_result['success']:
                return batch_result
            
            batch_id = batch_result['batch_id']
            print(f"âœ… æ‰¹æ¬¡IDç”ŸæˆæˆåŠŸ: {batch_id}")
            
            # ç¬¬äºŒæ­¥ï¼šç­‰å¾…å¤„ç†å®Œæˆ - è½®è¯¢æ£€æŸ¥çŠ¶æ€
            print("â³ ç­‰å¾…å¤„ç†å®Œæˆ...")
            max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
            check_interval = 10   # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                # æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€
                status_result = self.check_batch_status(batch_id)
                if not status_result['success']:
                    print(f"âŒ æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {status_result['error']}")
                    time.sleep(check_interval)
                    continue
                
                if status_result['is_complete']:
                    print(f"âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼æˆåŠŸ: {status_result['completed_files']}/{status_result['total_files']}")
                    break
                else:
                    print(f"â³ æ‰¹æ¬¡å¤„ç†ä¸­: {status_result['completed_files']}/{status_result['total_files']} (å·²ç­‰å¾… {int(time.time() - start_time)} ç§’)")
                    time.sleep(check_interval)
            else:
                return {
                    'success': False,
                    'error': f'æ‰¹æ¬¡å¤„ç†è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
                }
            
            # ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½ç»“æœï¼ˆå¯¹åº”test_output.pyï¼‰
            download_result = self.download_by_batch_idx(batch_id, output_dir)
            
            if download_result['success']:
                return {
                    'success': True,
                    'batch_id': batch_id,
                    'processed_files': download_result['processed_files'],
                    'success_count': download_result['success_count'],
                    'total_count': download_result['total_count'],
                    'output_dir': output_dir,
                    'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {download_result["success_count"]}/{download_result["total_count"]}'
                }
            else:
                return download_result
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}'
            }
    
    def check_task_status(self, task_id):
        """æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
        try:
            response = self.session.get(
                f"{self.base_url}/extract/task/{task_id}",
                headers=self.headers
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 0:
                    data = result.get('data', {})
                    return {
                        'success': True,
                        'state': data.get('state'),
                        'zip_url': data.get('full_zip_url'),
                        'error_msg': data.get('err_msg', '')
                    }
                else:
                    return {
                        'success': False,
                        'error': result.get('msg', 'è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥')
                    }
            else:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}'
            }
    
    def download_and_extract_result(self, zip_url, output_dir):
        """ä¸‹è½½å¹¶è§£å‹ç»“æœæ–‡ä»¶"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ä»URLä¸­æå–æ–‡ä»¶å
            parsed_url = urlparse(zip_url)
            filename = os.path.basename(parsed_url.path)
            if not filename.endswith('.zip'):
                filename = f"mineru_result_{int(time.time())}.zip"
            
            zip_path = output_path / filename
            
            print(f"å¼€å§‹ä¸‹è½½æ–‡ä»¶: {zip_url}")
            print(f"ä¿å­˜åˆ°: {zip_path}")
            
            # ä¸‹è½½æ–‡ä»¶
            response = self.session.get(zip_url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\rä¸‹è½½è¿›åº¦: {percent:.1f}%", end='', flush=True)
            
            print(f"\nä¸‹è½½å®Œæˆ: {zip_path}")
            
            # è§£å‹æ–‡ä»¶
            extract_dir = output_path / filename.replace('.zip', '')
            print(f"å¼€å§‹è§£å‹åˆ°: {extract_dir}")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            print(f"è§£å‹å®Œæˆ: {extract_dir}")
            
            # æŸ¥æ‰¾markdownæ–‡ä»¶
            md_files = list(extract_dir.rglob("*.md"))
            if md_files:
                # å°†markdownæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºç›®å½•çš„æ ¹ç›®å½•
                md_file = md_files[0]
                target_md = extract_dir / "result.md"
                md_file.rename(target_md)
                print(f"æ‰¾åˆ°markdownæ–‡ä»¶: {target_md}")
            
            # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
            image_files = list(extract_dir.rglob("*.jpg")) + list(extract_dir.rglob("*.png"))
            if image_files:
                # åˆ›å»ºimagesç›®å½•
                images_dir = extract_dir / "images"
                images_dir.mkdir(exist_ok=True)
                
                # ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶åˆ°imagesç›®å½•
                for img_file in image_files:
                    target_img = images_dir / img_file.name
                    img_file.rename(target_img)
                    print(f"ç§»åŠ¨å›¾ç‰‡æ–‡ä»¶: {target_img}")
            
            return {
                'success': True,
                'extract_dir': str(extract_dir),
                'md_file': str(extract_dir / "result.md") if md_files else None,
                'images_dir': str(extract_dir / "images") if image_files else None
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ä¸‹è½½æˆ–è§£å‹å¤±è´¥: {str(e)}'
            }
    
    def get_batch_results(self, batch_id, output_dir):
        """è·å–æ‰¹é‡å¤„ç†ç»“æœ"""
        try:
            print(f"ğŸ“¦ è·å–æ‰¹é‡å¤„ç†ç»“æœ: {batch_id}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # è·å–æ‰¹é‡ç»“æœ
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹é‡ç»“æœå¤±è´¥')
                }
            
            # å¤„ç†ç»“æœæ•°æ®
            data_list = batch_data['data']['extract_result']
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item['file_name']
                    
                    # ç”Ÿæˆæœ€ç»ˆè·¯å¾„
                    base_name = os.path.splitext(original_name)[0]
                    final_filename = f"{base_name}.md"
                    output_file_path = output_path / final_filename
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = output_path / f"temp_{item['data_id']}"
                        temp_dir.mkdir(exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = temp_dir / zip_name
                        
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹å¹¶å¤„ç†æ–‡ä»¶
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            # æœç´¢full.mdæ–‡ä»¶
                            target_file = None
                            for file_info in zip_ref.infolist():
                                if os.path.basename(file_info.filename) == 'full.md':
                                    target_file = file_info
                                    break
                            
                            if target_file:
                                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                                zip_ref.extract(target_file, temp_dir)
                                
                                # æ„å»ºå®Œæ•´è·¯å¾„
                                extracted_path = temp_dir / target_file.filename
                                
                                # ç§»åŠ¨å¹¶é‡å‘½å
                                shutil.move(str(extracted_path), str(output_file_path))
                                print(f"âœ… æˆåŠŸå¤„ç†ï¼š{original_name} -> {output_file_path}")
                                
                                processed_files.append({
                                    'original_name': original_name,
                                    'output_path': str(output_file_path),
                                    'success': True
                                })
                            else:
                                print(f"âš ï¸ è­¦å‘Šï¼š{zip_name} ä¸­æœªæ‰¾åˆ°full.mdæ–‡ä»¶")
                                processed_files.append({
                                    'original_name': original_name,
                                    'output_path': None,
                                    'success': False,
                                    'error': 'æœªæ‰¾åˆ°full.mdæ–‡ä»¶'
                                })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"âŒ æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"âŒ å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'output_path': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if temp_dir.exists():
                            shutil.rmtree(temp_dir)
            
            return {
                'success': True,
                'processed_files': processed_files,
                'output_dir': str(output_path)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è·å–æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}'
            }
    
    def submit_batch_task(self, file_paths, is_ocr=True, enable_formula=True, language="en", layout_model="doclayout_yolo", enable_table=True, max_files_per_batch=200):
        """æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡"""
        try:
            print(f"ğŸ“¦ æäº¤æ‰¹é‡å¤„ç†ä»»åŠ¡ï¼Œæ–‡ä»¶æ•°é‡: {len(file_paths)}")
            
            # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
            all_batch_ids = []
            total_files = len(file_paths)
            
            for batch_idx in range(0, total_files, max_files_per_batch):
                batch_files = file_paths[batch_idx:batch_idx + max_files_per_batch]
                print(f"å¤„ç†ç¬¬ {batch_idx // max_files_per_batch + 1} æ‰¹æ¬¡ï¼Œæ–‡ä»¶æ•°é‡: {len(batch_files)}")
                
                # æ„å»ºæ–‡ä»¶æ•°æ®
                files_data = []
                for file_path in batch_files:
                    if os.path.exists(file_path):
                        files_data.append({
                            "name": os.path.basename(file_path),
                            "is_ocr": is_ocr,
                            "data_id": f"{os.path.splitext(os.path.basename(file_path))[0]}_b{batch_idx // max_files_per_batch + 1}",
                            "language": language,
                        })
                
                if not files_data:
                    print(f"æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶")
                    continue
                
                # æäº¤æ‰¹æ¬¡ä»»åŠ¡
                batch_result = self._submit_single_batch(files_data, batch_files, enable_formula, language, layout_model, enable_table)
                if batch_result['success']:
                    all_batch_ids.append(batch_result['batch_id'])
                    print(f"âœ… æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æäº¤æˆåŠŸï¼Œæ‰¹æ¬¡ID: {batch_result['batch_id']}")
                else:
                    print(f"âŒ æ‰¹æ¬¡ {batch_idx // max_files_per_batch + 1} æäº¤å¤±è´¥: {batch_result['error']}")
            
            if all_batch_ids:
                return {
                    'success': True,
                    'batch_ids': all_batch_ids,
                    'message': f'æˆåŠŸæäº¤ {len(all_batch_ids)} ä¸ªæ‰¹æ¬¡'
                }
            else:
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰æ‰¹æ¬¡æäº¤å¤±è´¥'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æäº¤æ‰¹é‡ä»»åŠ¡å¤±è´¥: {str(e)}'
            }
    
    def _submit_single_batch(self, files_data, file_paths, enable_formula, language, layout_model, enable_table):
        """æäº¤å•ä¸ªæ‰¹æ¬¡ä»»åŠ¡"""
        try:
            # è·å–ä¸Šä¼ URL
            response = self.session.post(
                f"{self.base_url}/file-urls/batch",
                headers=self.headers,
                json={
                    "enable_formula": enable_formula,
                    "language": language,
                    "layout_model": layout_model,
                    "enable_table": enable_table,
                    "files": files_data
                }
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}'
                }
            
            result = response.json()
            if result["code"] != 0:
                return {
                    'success': False,
                    'error': f'ç”³è¯·å¤±è´¥ï¼ŒåŸå› ï¼š{result.get("msg", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¸Šä¼ æ–‡ä»¶
            batch_id = result["data"]["batch_id"]
            urls = result["data"]["file_urls"]
            success_count = 0
            
            for idx, (url, file_path) in enumerate(zip(urls, file_paths)):
                if os.path.exists(file_path):
                    with open(file_path, 'rb') as f:
                        res = self.session.put(url, data=f)
                        if res.status_code in [200, 201]:
                            success_count += 1
                        else:
                            print(f"âŒ å¤±è´¥æ–‡ä»¶ï¼š{os.path.basename(file_path)}ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}")
            
            print(f"ğŸ“¤ æ‰¹æ¬¡ä¸Šä¼ å®Œæˆ | æˆåŠŸï¼š{success_count}/{len(file_paths)} | æ‰¹æ¬¡IDï¼š{batch_id}")
            
            return {
                'success': True,
                'batch_id': batch_id,
                'uploaded_count': success_count,
                'total_count': len(file_paths)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æäº¤æ‰¹æ¬¡å¤±è´¥: {str(e)}'
            }
    
    def check_batch_status(self, batch_id):
        """æ£€æŸ¥æ‰¹é‡å¤„ç†çŠ¶æ€"""
        try:
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹é‡çŠ¶æ€å¤±è´¥')
                }
            
            # åˆ†æå¤„ç†çŠ¶æ€
            data_list = batch_data['data']['extract_result']
            total_files = len(data_list)
            completed_files = len([item for item in data_list if item.get('state') == 'done'])
            failed_files = len([item for item in data_list if item.get('state') == 'failed'])
            processing_files = len([item for item in data_list if item.get('state') == 'processing'])
            
            return {
                'success': True,
                'batch_id': batch_id,
                'total_files': total_files,
                'completed_files': completed_files,
                'failed_files': failed_files,
                'processing_files': processing_files,
                'is_complete': completed_files + failed_files == total_files,
                'data_list': data_list
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æ£€æŸ¥æ‰¹é‡çŠ¶æ€å¤±è´¥: {str(e)}'
            }
    
    def download_batch_results(self, batch_id, output_dir):
        """ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ"""
        try:
            print(f"ğŸ“¥ ä¸‹è½½æ‰¹é‡å¤„ç†ç»“æœ: {batch_id}")
            
            # æ£€æŸ¥æ‰¹é‡çŠ¶æ€
            status_result = self.check_batch_status(batch_id)
            if not status_result['success']:
                return status_result
            
            if not status_result['is_complete']:
                return {
                    'success': False,
                    'error': f'æ‰¹é‡å¤„ç†æœªå®Œæˆï¼Œå·²å®Œæˆ: {status_result["completed_files"]}/{status_result["total_files"]}'
                }
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            data_list = status_result['data_list']
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item['file_name']
                    data_id = item['data_id']
                    
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„ç›®å½•ï¼Œä½¿ç”¨data_idä½œä¸ºç›®å½•å
                    file_output_dir = output_path / data_id
                    file_output_dir.mkdir(exist_ok=True)
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = output_path / f"temp_{data_id}"
                        temp_dir.mkdir(exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = temp_dir / zip_name
                        
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹æ•´ä¸ªZIPæ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(file_output_dir)
                            print(f"âœ… æˆåŠŸå¤„ç†ï¼š{original_name} -> {file_output_dir}")
                        
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': str(file_output_dir),
                            'success': True
                        })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"âŒ æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"âŒ å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if temp_dir.exists():
                            shutil.rmtree(temp_dir)
                elif item.get('state') == 'failed':
                    print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': 'æ–‡ä»¶å¤„ç†å¤±è´¥'
                    })
            
            return {
                'success': True,
                'batch_id': batch_id,
                'processed_files': processed_files,
                'output_dir': str(output_path)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ä¸‹è½½æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}'
            }
    
    def process_batch_files(self, file_paths, output_dir, is_ocr=True, enable_formula=True, language="en", max_wait_time=1800):
        """å¤„ç†æ‰¹é‡æ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
        try:
            print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
            
            # 1. æäº¤æ‰¹é‡ä»»åŠ¡
            submit_result = self.submit_batch_task(
                file_paths, 
                is_ocr=is_ocr, 
                enable_formula=enable_formula, 
                language=language
            )
            if not submit_result['success']:
                return submit_result
            
            batch_ids = submit_result['batch_ids']
            print(f"ğŸ“‹ æˆåŠŸæäº¤ {len(batch_ids)} ä¸ªæ‰¹æ¬¡")
            
            # 2. ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
            print("â³ ç­‰å¾…æ‰¹é‡å¤„ç†å®Œæˆ...")
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                all_complete = True
                
                for batch_id in batch_ids:
                    status_result = self.check_batch_status(batch_id)
                    if not status_result['success']:
                        print(f"âŒ æ£€æŸ¥æ‰¹æ¬¡ {batch_id} çŠ¶æ€å¤±è´¥: {status_result['error']}")
                        continue
                    
                    if not status_result['is_complete']:
                        all_complete = False
                        print(f"â³ æ‰¹æ¬¡ {batch_id} å¤„ç†ä¸­: {status_result['completed_files']}/{status_result['total_files']}")
                
                if all_complete:
                    print("âœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆ")
                    break
                
                # ç­‰å¾…30ç§’åå†æ¬¡æ£€æŸ¥
                time.sleep(30)
            
            if not all_complete:
                return {
                    'success': False,
                    'error': f'æ‰¹é‡å¤„ç†è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
                }
            
            # 3. ä¸‹è½½æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
            all_processed_files = []
            for batch_id in batch_ids:
                download_result = self.download_batch_results(batch_id, output_dir)
                if download_result['success']:
                    all_processed_files.extend(download_result['processed_files'])
                else:
                    print(f"âŒ ä¸‹è½½æ‰¹æ¬¡ {batch_id} ç»“æœå¤±è´¥: {download_result['error']}")
            
            success_count = len([f for f in all_processed_files if f['success']])
            total_count = len(all_processed_files)
            
            return {
                'success': True,
                'processed_files': all_processed_files,
                'success_count': success_count,
                'total_count': total_count,
                'output_dir': output_dir,
                'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{total_count}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}'
            }

    def generate_batch_idx(self, file_paths, batch_index=0, max_files_per_batch=200, language="ch", is_ocr=True, enable_formula=True, enable_table=True, layout_model="doclayout_yolo"):
        """ç”Ÿæˆæ‰¹æ¬¡ID - å¯¹åº”test_input.pyçš„åŠŸèƒ½"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            valid_files = []
            for file_path in file_paths:
                if os.path.exists(file_path):
                    valid_files.append(file_path)
                else:
                    print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
            
            if not valid_files:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯å¤„ç†'
                }
            
            print(f"æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
            print(f"å¤„ç†ç¬¬ {batch_index} æ‰¹æ¬¡")
            
            # è®¡ç®—æ‰¹æ¬¡æ–‡ä»¶èŒƒå›´
            batch_idx = max_files_per_batch * batch_index
            batch_files = valid_files[batch_idx : batch_idx + max_files_per_batch]
            
            if not batch_files:
                return {
                    'success': False,
                    'error': f'ç¬¬ {batch_index} æ‰¹æ¬¡æ²¡æœ‰æ–‡ä»¶å¯å¤„ç†'
                }
            
            # æ„å»ºæ–‡ä»¶æ•°æ®
            files_data = [{
                "name": os.path.basename(file_path),
                "is_ocr": is_ocr,
                "data_id": f"{os.path.splitext(os.path.basename(file_path))[0]}_b{batch_index + 1}",
                "language": language,
            } for file_path in batch_files]
            
            print(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_index + 1} æ‰¹æ¬¡ï¼ˆå…± {len(batch_files)} ä¸ªæ–‡ä»¶ï¼‰")
            
            # è·å–ä¸Šä¼ URL
            response = self.session.post(
                f"{self.base_url}/file-urls/batch",
                headers=self.headers,
                json={
                    "enable_formula": enable_formula,
                    "language": language,
                    "layout_model": layout_model,
                    "enable_table": enable_table,
                    "files": files_data
                }
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}'
                }
            
            result = response.json()
            if result["code"] != 0:
                return {
                    'success': False,
                    'error': f'ç”³è¯·å¤±è´¥ï¼ŒåŸå› ï¼š{result.get("msg", "æœªçŸ¥é”™è¯¯")}'
                }
            
            # ä¸Šä¼ æ–‡ä»¶
            batch_id = result["data"]["batch_id"]
            urls = result["data"]["file_urls"]
            success_count = 0
            
            for idx, (url, file_path) in enumerate(zip(urls, batch_files)):
                with open(file_path, 'rb') as f:
                    res = self.session.put(url, data=f)
                    if res.status_code in [200, 201]:
                        success_count += 1
                    else:
                        print(f"å¤±è´¥æ–‡ä»¶ï¼š{os.path.basename(file_path)}ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}")
            
            print(f"ç¬¬ {batch_index + 1} æ‰¹æ¬¡å®Œæˆ | æˆåŠŸï¼š{success_count}/{len(batch_files)} | æ‰¹æ¬¡IDï¼š{batch_id}")
            
            return {
                'success': True,
                'batch_id': batch_id,
                'uploaded_count': success_count,
                'total_count': len(batch_files),
                'message': f'ç¬¬ {batch_index + 1} æ‰¹æ¬¡æäº¤æˆåŠŸï¼Œæ‰¹æ¬¡ID: {batch_id}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ‰¹æ¬¡IDå¤±è´¥: {str(e)}'
            }
    
    def download_by_batch_idx(self, batch_id, output_dir):
        """åˆ©ç”¨æ‰¹æ¬¡IDä¸‹è½½ç»“æœ - å¯¹åº”test_output.pyçš„åŠŸèƒ½"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            print(f"å¼€å§‹ä¸‹è½½æ‰¹æ¬¡ {batch_id} çš„ç»“æœ...")
            
            # å…ˆæ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½å¤„ç†å®Œæˆ
            status_result = self.check_batch_status(batch_id)
            if not status_result['success']:
                return {
                    'success': False,
                    'error': f'æ£€æŸ¥æ‰¹æ¬¡çŠ¶æ€å¤±è´¥: {status_result["error"]}'
                }
            
            if not status_result['is_complete']:
                return {
                    'success': False,
                    'error': f'æ‰¹æ¬¡å¤„ç†æœªå®Œæˆï¼Œå·²å®Œæˆ: {status_result["completed_files"]}/{status_result["total_files"]}ï¼Œè¯·ç¨åé‡è¯•'
                }
            
            # è·å–æ‰¹æ¬¡ç»“æœ
            response = self.session.get(
                f"{self.base_url}/extract-results/batch/{batch_id}",
                headers=self.headers
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f'HTTPé”™è¯¯: {response.status_code}'
                }
            
            batch_data = response.json()
            if batch_data.get('code') != 0:
                return {
                    'success': False,
                    'error': batch_data.get('msg', 'è·å–æ‰¹æ¬¡ç»“æœå¤±è´¥')
                }
            
            # æ­£ç¡®è®¿é—®æ•°æ®è·¯å¾„
            data_list = batch_data['data']['extract_result']
            
            processed_files = []
            
            for item in data_list:
                if item.get('state') == 'done' and 'full_zip_url' in item:
                    zip_url = item['full_zip_url']
                    original_name = item['file_name']
                    data_id = item['data_id']
                    
                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„ç›®å½•ï¼Œä½¿ç”¨data_idä½œä¸ºç›®å½•å
                    file_output_dir = os.path.join(output_dir, data_id)
                    os.makedirs(file_output_dir, exist_ok=True)
                    
                    try:
                        # åˆ›å»ºä¸´æ—¶ç›®å½•
                        temp_dir = os.path.join(output_dir, f"temp_{data_id}")
                        os.makedirs(temp_dir, exist_ok=True)
                        
                        # ä¸‹è½½ZIPæ–‡ä»¶
                        zip_response = self.session.get(zip_url, stream=True)
                        zip_response.raise_for_status()
                        
                        # ä¿å­˜ä¸´æ—¶ZIP
                        zip_name = os.path.basename(urlparse(zip_url).path)
                        zip_path = os.path.join(temp_dir, zip_name)
                        with open(zip_path, 'wb') as f:
                            for chunk in zip_response.iter_content(1024 * 1024):  # 1MB chunks
                                f.write(chunk)
                        
                        # è§£å‹æ•´ä¸ªZIPæ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(file_output_dir)
                            print(f"æˆåŠŸå¤„ç†ï¼š{original_name} -> {file_output_dir}")
                        
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': file_output_dir,
                            'success': True
                        })
                        
                    except requests.exceptions.RequestException as e:
                        print(f"ä¸‹è½½å¤±è´¥ï¼š{original_name} | é”™è¯¯ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
                        })
                    except zipfile.BadZipFile:
                        print(f"æŸåçš„ZIPæ–‡ä»¶ï¼š{original_name}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': 'æŸåçš„ZIPæ–‡ä»¶'
                        })
                    except Exception as e:
                        print(f"å¤„ç†å¼‚å¸¸ï¼š{original_name} | é”™è¯¯ç±»å‹ï¼š{type(e).__name__} | è¯¦æƒ…ï¼š{str(e)}")
                        processed_files.append({
                            'original_name': original_name,
                            'data_id': data_id,
                            'output_dir': None,
                            'success': False,
                            'error': f'å¤„ç†å¼‚å¸¸: {str(e)}'
                        })
                    finally:
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_dir):
                            shutil.rmtree(temp_dir)
                elif item.get('state') == 'running':
                    print(f"â³ æ–‡ä»¶ä»åœ¨å¤„ç†ä¸­ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')} - çŠ¶æ€: {item.get('state')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': 'æ–‡ä»¶ä»åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åé‡è¯•'
                    })
                else:
                    print(f"æ–‡ä»¶å¤„ç†çŠ¶æ€å¼‚å¸¸ï¼š{item.get('file_name', 'æœªçŸ¥æ–‡ä»¶')} - {item.get('state', 'æœªçŸ¥çŠ¶æ€')}")
                    processed_files.append({
                        'original_name': item.get('file_name', 'æœªçŸ¥æ–‡ä»¶'),
                        'data_id': item.get('data_id', ''),
                        'output_dir': None,
                        'success': False,
                        'error': f'å¤„ç†çŠ¶æ€å¼‚å¸¸: {item.get("state", "æœªçŸ¥çŠ¶æ€")}'
                    })
            
            success_count = len([f for f in processed_files if f['success']])
            total_count = len(processed_files)
            
            return {
                'success': True,
                'batch_id': batch_id,
                'processed_files': processed_files,
                'success_count': success_count,
                'total_count': total_count,
                'output_dir': output_dir,
                'message': f'æ‰¹æ¬¡ {batch_id} ä¸‹è½½å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{total_count}'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'åˆ©ç”¨æ‰¹æ¬¡IDä¸‹è½½å¤±è´¥: {str(e)}'
            }

    def process_file(self, file_path, output_dir, is_ocr=True, enable_formula=False, max_wait_time=300):
        """å¤„ç†æ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
        try:
            # 1. æäº¤ä»»åŠ¡
            print("æäº¤æ–‡ä»¶å¤„ç†ä»»åŠ¡...")
            submit_result = self.submit_task(file_path, is_ocr, enable_formula)
            if not submit_result['success']:
                return submit_result
            
            task_id = submit_result['task_id']
            print(f"ä»»åŠ¡ID: {task_id}")
            
            # 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€
            print("ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
            start_time = time.time()
            
            while time.time() - start_time < max_wait_time:
                status_result = self.check_task_status(task_id)
                if not status_result['success']:
                    return status_result
                
                state = status_result['state']
                print(f"ä»»åŠ¡çŠ¶æ€: {state}")
                
                if state == 'done':
                    zip_url = status_result['zip_url']
                    if zip_url:
                        # 3. ä¸‹è½½å¹¶è§£å‹ç»“æœ
                        print("ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½ç»“æœ...")
                        return self.download_and_extract_result(zip_url, output_dir)
                    else:
                        return {
                            'success': False,
                            'error': 'ä»»åŠ¡å®Œæˆä½†æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥'
                        }
                elif state == 'failed':
                    return {
                        'success': False,
                        'error': f'ä»»åŠ¡å¤±è´¥: {status_result.get("error_msg", "æœªçŸ¥é”™è¯¯")}'
                    }
                
                # ç­‰å¾…5ç§’åå†æ¬¡æ£€æŸ¥
                time.sleep(5)
            
            return {
                'success': False,
                'error': f'ä»»åŠ¡è¶…æ—¶ï¼Œç­‰å¾…æ—¶é—´è¶…è¿‡{max_wait_time}ç§’'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'å¤„ç†æ–‡ä»¶å¤±è´¥: {str(e)}'
            }
